{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca833eae",
   "metadata": {},
   "source": [
    "### Segmentação de Imagens e Avaliação de Qualidade de Segmentação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4172ac23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMódulo para segmentação de imagens utilizando Fuzzy\\xa0C‑Means (FCM) e K‑Means.\\n\\nEste módulo reorganiza o código original em funções menores e independentes para\\nfacilitar o reuso e a manipulação dos resultados intermediários. As máscaras de\\nsegmentação (rótulos) são retornadas explicitamente pelas funções de\\nsegmentação. Dessa forma, você pode acessar e manipular diretamente as\\nmascaras produzidas pelos algoritmos, sem necessidade de percorrer\\nestruturas complexas.\\n\\nFunções principais:\\n\\n* ``load_gray_norm``: carrega uma imagem em escala de cinza e normaliza no\\n  intervalo ``[0,\\xa01]``.\\n* ``cmeans_labels``: aplica o algoritmo Fuzzy\\xa0C‑Means (FCM) e retorna as\\n  máscaras (labels) e centros.\\n* ``kmeans_labels``: aplica o algoritmo K‑Means e retorna as máscaras (labels)\\n  e centros.\\n* ``run_fcm`` e ``run_kmeans``: funções utilitárias que executam FCM ou\\n  K‑Means, medindo o tempo de execução e calculando as métricas internas de\\n  validação de cluster. Cada função retorna um dicionário com as máscaras,\\n  métricas e tempo de processamento.\\n* ``evaluate_clustering`` e ``dunn_index``: funções de avaliação que\\n  calculam índices internos como Davies–Bouldin, Calinski–Harabasz e Dunn.\\n* ``plot_comparison``: gera uma figura comparando lado a lado as máscaras de\\n  FCM e K‑Means.\\n* ``segment_image``: orquestra a segmentação de uma única imagem chamando\\n  ``run_fcm`` e ``run_kmeans`` e opcionalmente gerando um gráfico de\\n  comparação.\\n\\nO objetivo é permitir que cada parte do processamento (carregamento,\\nsegmentação, avaliação e visualização) seja tratada de forma isolada. Isso\\nfacilita o teste e o reaproveitamento das etapas em outros projetos. Se você\\ndeseja acessar diretamente as máscaras de segmentação, elas são retornadas\\npelas funções ``run_fcm`` e ``run_kmeans`` nos campos ``\"labels\"``.\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Módulo para segmentação de imagens utilizando Fuzzy C‑Means (FCM) e K‑Means.\n",
    "\n",
    "Este módulo reorganiza o código original em funções menores e independentes para\n",
    "facilitar o reuso e a manipulação dos resultados intermediários. As máscaras de\n",
    "segmentação (rótulos) são retornadas explicitamente pelas funções de\n",
    "segmentação. Dessa forma, você pode acessar e manipular diretamente as\n",
    "mascaras produzidas pelos algoritmos, sem necessidade de percorrer\n",
    "estruturas complexas.\n",
    "\n",
    "Funções principais:\n",
    "\n",
    "* ``load_gray_norm``: carrega uma imagem em escala de cinza e normaliza no\n",
    "  intervalo ``[0, 1]``.\n",
    "* ``cmeans_labels``: aplica o algoritmo Fuzzy C‑Means (FCM) e retorna as\n",
    "  máscaras (labels) e centros.\n",
    "* ``kmeans_labels``: aplica o algoritmo K‑Means e retorna as máscaras (labels)\n",
    "  e centros.\n",
    "* ``run_fcm`` e ``run_kmeans``: funções utilitárias que executam FCM ou\n",
    "  K‑Means, medindo o tempo de execução e calculando as métricas internas de\n",
    "  validação de cluster. Cada função retorna um dicionário com as máscaras,\n",
    "  métricas e tempo de processamento.\n",
    "* ``evaluate_clustering`` e ``dunn_index``: funções de avaliação que\n",
    "  calculam índices internos como Davies–Bouldin, Calinski–Harabasz e Dunn.\n",
    "* ``plot_comparison``: gera uma figura comparando lado a lado as máscaras de\n",
    "  FCM e K‑Means.\n",
    "* ``segment_image``: orquestra a segmentação de uma única imagem chamando\n",
    "  ``run_fcm`` e ``run_kmeans`` e opcionalmente gerando um gráfico de\n",
    "  comparação.\n",
    "\n",
    "O objetivo é permitir que cada parte do processamento (carregamento,\n",
    "segmentação, avaliação e visualização) seja tratada de forma isolada. Isso\n",
    "facilita o teste e o reaproveitamento das etapas em outros projetos. Se você\n",
    "deseja acessar diretamente as máscaras de segmentação, elas são retornadas\n",
    "pelas funções ``run_fcm`` e ``run_kmeans`` nos campos ``\"labels\"``.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc833d33",
   "metadata": {},
   "source": [
    "## Bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "427f323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, List, Any\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score, calinski_harabasz_score\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from numpy.random import default_rng\n",
    "from typing import Optional, Any, Dict, Tuple\n",
    "\n",
    "from docplex.mp.model import Model\n",
    "from qiskit.primitives import StatevectorSampler\n",
    "from qiskit_optimization.algorithms import CobylaOptimizer, MinimumEigenOptimizer\n",
    "from qiskit_optimization.algorithms.admm_optimizer import ADMMOptimizer, ADMMParameters, UPDATE_RHO_BY_RESIDUALS\n",
    "from qiskit_optimization.minimum_eigensolvers import QAOA, NumPyMinimumEigensolver\n",
    "from qiskit_optimization.optimizers import COBYLA\n",
    "#from qiskit_optimization.translators import from_docplex_mp\n",
    "from qiskit_optimization import QuadraticProgram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43e5112",
   "metadata": {},
   "source": [
    "## Funções Utilitárias (Carregamento e Normalização)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "19916056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_normalization(\n",
    "    img: np.ndarray,\n",
    "    normalize: Optional[str] = None,\n",
    "    params: Optional[Dict[str, float]] = None,\n",
    ") -> Tuple[np.ndarray, Optional[Dict[str, float]]]:\n",
    "    \"\"\"\n",
    "    Normaliza opcionalmente a imagem.\n",
    "    normalize: None | 'minmax' | 'zscore'\n",
    "    params (opcional): dict com chaves esperadas por método escolhido:\n",
    "        - 'min','max' para minmax\n",
    "        - 'mean','std' para zscore\n",
    "    Retorna (img_norm, used_params)\n",
    "    \"\"\"\n",
    "    if normalize is None:\n",
    "        return img, None\n",
    "\n",
    "    if normalize == 'minmax':\n",
    "        if params is None:\n",
    "            mn = float(np.min(img))\n",
    "            mx = float(np.max(img))\n",
    "        else:\n",
    "            mn = float(params.get('min', np.min(img)))\n",
    "            mx = float(params.get('max', np.max(img)))\n",
    "        denom = (mx - mn) + 1e-10\n",
    "        out = (img - mn) / denom\n",
    "        return out, {'method': 'minmax', 'min': mn, 'max': mx}\n",
    "\n",
    "    if normalize == 'zscore':\n",
    "        if params is None:\n",
    "            mu = float(np.mean(img))\n",
    "            sd = float(np.std(img))\n",
    "        else:\n",
    "            mu = float(params.get('mean', np.mean(img)))\n",
    "            sd = float(params.get('std',  np.std(img)))\n",
    "        out = (img - mu) / (sd + 1e-10)\n",
    "        return out, {'method': 'zscore', 'mean': mu, 'std': sd}\n",
    "\n",
    "    # método desconhecido -> não normaliza\n",
    "    return img, None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_gray_norm(path: Path) -> np.ndarray:\n",
    "    \"\"\"Carrega uma imagem em escala de cinza (L) e normaliza para o intervalo [0, 1].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : Path\n",
    "        Caminho para a imagem no disco.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Array 2‑D float32 com valores normalizados.\n",
    "    \"\"\"\n",
    "    # Abre a imagem em modo L (8‑bits) e converte para float32\n",
    "    arr = np.asarray(Image.open(path).convert(\"L\"), dtype=np.float32)\n",
    "    # Normaliza para [0,1] evitando divisão por zero\n",
    "    denom = (arr.max() - arr.min()) + 1e-10\n",
    "    return (arr - arr.min()) / denom\n",
    "\n",
    "\n",
    "def maybe_flip_binary(pred: np.ndarray, gt: np.ndarray) -> np.ndarray:\n",
    "    # Ex.: maximiza IoU (poderia ser acurácia, F1, etc.)\n",
    "    def iou(a, b):\n",
    "        inter = np.logical_and(a == 1, b == 1).sum()\n",
    "        union = np.logical_or(a == 1, b == 1).sum()\n",
    "        return inter / (union + 1e-10)\n",
    "\n",
    "    iou_orig = iou(pred, gt)\n",
    "    iou_flip = iou(1 - pred, gt)\n",
    "    return pred if iou_orig >= iou_flip else (1 - pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0edfaaa",
   "metadata": {},
   "source": [
    "## Funções de Segmentação:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223d54f3",
   "metadata": {},
   "source": [
    "### Fuzzy C-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "03c23d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmeans_labels(\n",
    "    features: np.ndarray,\n",
    "    n_clusters: int = 2,\n",
    "    m: float = 2,\n",
    "    error: float = 1e-5,\n",
    "    maxiter: int = 1000,\n",
    "    seed: int = 0,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Aplica o Fuzzy C‑Means e retorna rótulos e centros.\n",
    "\n",
    "    O input ``features`` pode ser uma imagem 2‑D ou uma matriz (H, W, K). Caso\n",
    "    possua duas dimensões, ela é expandida para possuir um canal adicional.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features : np.ndarray\n",
    "        Array de características com dimensão (H, W) ou (H, W, K), normalizado\n",
    "        em [0,1].\n",
    "    n_clusters : int, optional\n",
    "        Número de clusters desejados, por padrão 3.\n",
    "    m : float, optional\n",
    "        Parâmetro de fuzzificação (m > 1). Valores maiores resultam em\n",
    "        partições mais difusas. Padrão: 1.6.\n",
    "    error : float, optional\n",
    "        Critério de parada. A iteração termina quando a diferença entre\n",
    "        partições consecutivas for menor que ``error``. Padrão: 1e‑5.\n",
    "    maxiter : int, optional\n",
    "        Número máximo de iterações do algoritmo. Padrão: 1000.\n",
    "    seed : int, optional\n",
    "        Semente do gerador de números aleatórios. Padrão: 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[np.ndarray, np.ndarray]\n",
    "        ``labels`` : array 2‑D de inteiros com tamanho (H, W)\n",
    "            Rótulos de cluster atribuídos a cada pixel.\n",
    "        ``centers`` : array 2‑D com tamanho (n_clusters, K)\n",
    "            Centróides no espaço de características.\n",
    "    \"\"\"\n",
    "    # Garante que features tenha terceira dimensão (canal)\n",
    "    if features.ndim == 2:\n",
    "        features = features[..., None]\n",
    "    H, W, K = features.shape\n",
    "    # Transforma features em forma (N, K) para cálculos\n",
    "    X_flat = features.reshape(-1, K)  # shape (N, K)\n",
    "    N = X_flat.shape[0]\n",
    "    c = n_clusters\n",
    "    rng = default_rng(seed)\n",
    "    # Inicializa a matriz de pertinência U de forma aleatória\n",
    "    U = rng.random((c, N))\n",
    "    U /= U.sum(axis=0, keepdims=True)\n",
    "    # Iterações do algoritmo FCM\n",
    "    for _ in range(maxiter):\n",
    "        U_old = U.copy()\n",
    "        # Calcula os centros (c, K): soma((u_ik)^m * x_k) / soma((u_ik)^m)\n",
    "        um = U ** m\n",
    "        centers = um @ X_flat / um.sum(axis=1, keepdims=True)\n",
    "        # Distâncias dos centros aos pontos (c, N)\n",
    "        diff = X_flat[None, :, :] - centers[:, None, :]\n",
    "        dist = np.linalg.norm(diff, axis=2) + 1e-10  # evita divisão por zero\n",
    "        # Atualiza U (c, N)\n",
    "        power = 2.0 / (m - 1.0)\n",
    "        for i in range(c):\n",
    "            ratio = (dist[i] / dist) ** power  # shape (c, N)\n",
    "            denom = ratio.sum(axis=0)  # shape (N,)\n",
    "            U[i] = 1.0 / denom\n",
    "        # Verifica convergência\n",
    "        if np.max(np.abs(U - U_old)) < error:\n",
    "            break\n",
    "    labels = np.argmax(U, axis=0).reshape(H, W)\n",
    "    return labels, centers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed56de85",
   "metadata": {},
   "source": [
    "### K-Means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "069ee0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_labels(\n",
    "    features: np.ndarray,\n",
    "    n_clusters: int = 3,\n",
    "    seed: int = 0,\n",
    "    n_init: int = 10,\n",
    "    max_iter: int = 300,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Aplica K‑Means (scikit‑learn) e retorna rótulos e centros.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features : np.ndarray\n",
    "        Imagem ou matriz de características com dimensão (H, W) ou (H, W, K).\n",
    "    n_clusters : int, optional\n",
    "        Número de clusters desejados. Padrão: 3.\n",
    "    seed : int, optional\n",
    "        Semente do gerador de números aleatórios. Padrão: 0.\n",
    "    n_init : int, optional\n",
    "        Número de inicializações diferentes. O K‑Means será executado ``n_init``\n",
    "        vezes com diferentes centroides aleatórios e o melhor resultado será\n",
    "        escolhido (menor inércia). Padrão: 10.\n",
    "    max_iter : int, optional\n",
    "        Número máximo de iterações do algoritmo para uma única execução. Padrão:\n",
    "        300.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[np.ndarray, np.ndarray]\n",
    "        ``labels`` : array 2‑D de inteiros com tamanho (H, W)\n",
    "            Rótulos de cluster atribuídos a cada pixel.\n",
    "        ``centers`` : array 2‑D com tamanho (n_clusters, K)\n",
    "            Centróides no espaço de características.\n",
    "    \"\"\"\n",
    "    if features.ndim == 2:\n",
    "        features = features[..., None]\n",
    "    H, W, K = features.shape\n",
    "    X = features.reshape(-1, K)  # shape (N, K)\n",
    "    kmeans = KMeans(\n",
    "        n_clusters=n_clusters,\n",
    "        random_state=seed,\n",
    "        n_init=n_init,\n",
    "        max_iter=max_iter,\n",
    "    )\n",
    "    labels_flat = kmeans.fit_predict(X)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    labels = labels_flat.reshape(H, W)\n",
    "    return labels, centers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced696ac-8541-48fa-99fc-898c242f6ecb",
   "metadata": {},
   "source": [
    "### QFFCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9096e842-62e4-4b62-9fa1-fcf4c0bcd647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmeans_labels(\n",
    "    features: np.ndarray,\n",
    "    n_clusters: int = 2,\n",
    "    m: float = 2.0,         # m = 2\n",
    "    error: float = 1e-3,    # error = 1e-2\n",
    "    maxiter: int = 20,\n",
    "    nbins: int = 8,\n",
    "    seed: int = 0,\n",
    "    lambda_s: float = 50.0,\n",
    "    mu_s: float = 10.0,\n",
    "    alpha: float = 0.1,     # alpha = 0.1\n",
    "    rho_initial: float = 20.0,  # rho = 20\n",
    "    beta_rho: float = 2.0,      # beta_rho = 2\n",
    "    admm_inner_maxiter: int = 3,  # admm_inner_maxiter = 3\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    QFFCM = Fast FCM + 3-ADMM-H + QAOA\n",
    "    \"\"\"\n",
    "    if features.ndim != 2:\n",
    "        raise ValueError(\n",
    "            f\"QFFCM implementado aqui apenas para imagens 2D (H,W); recebi ndim={features.ndim}.\"\n",
    "        )\n",
    "\n",
    "    H, W = features.shape\n",
    "    vals = features.astype(np.float64).ravel()  # (N,)\n",
    "\n",
    "    vmin = float(vals.min())\n",
    "    vmax = float(vals.max()) + 1e-12\n",
    "\n",
    "    hist, bin_edges = np.histogram(vals, bins=nbins, range=(vmin, vmax)) # Reduzindo de N pixels para L bins\n",
    "    bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])  # (L,)\n",
    "    weights = hist.astype(np.float64)                     # (L,)\n",
    "    L = bin_centers.shape[0]\n",
    "\n",
    "    if np.all(weights == 0):\n",
    "        labels = np.zeros((H, W), dtype=int)\n",
    "        centers = np.array([[vmin]], dtype=np.float64)\n",
    "        return labels, centers\n",
    "\n",
    "    rng = default_rng(seed)\n",
    "    C = n_clusters\n",
    "\n",
    "    nonzero_bins = np.where(weights > 0)[0] # Inicialização dos clusters\n",
    "    if len(nonzero_bins) >= C:\n",
    "        init_idx = rng.choice(nonzero_bins, size=C, replace=False)\n",
    "    else:\n",
    "        init_idx = rng.choice(L, size=C, replace=False)\n",
    "\n",
    "    V = bin_centers[init_idx].reshape(C, 1)   # (C,1)\n",
    "\n",
    "    sampler = StatevectorSampler(seed=seed)\n",
    "    inner_qaoa = QAOA(\n",
    "        sampler=sampler,\n",
    "        reps=3,                       # reps = 3 (profundidade QAOA)\n",
    "        optimizer=COBYLA(maxiter=10),\n",
    "    )\n",
    "    qubo_optimizer = MinimumEigenOptimizer(inner_qaoa)\n",
    "    cont_optimizer = CobylaOptimizer()\n",
    "\n",
    "    admm_params = ADMMParameters(\n",
    "        rho_initial=rho_initial,\n",
    "        beta=beta_rho,\n",
    "        factor_c=10.0,\n",
    "        maxiter=admm_inner_maxiter,\n",
    "        three_block=True,\n",
    "        vary_rho=UPDATE_RHO_BY_RESIDUALS,\n",
    "        tau_incr=2.0,\n",
    "        tau_decr=2.0,\n",
    "        mu_res=10.0,\n",
    "    )\n",
    "    admm = ADMMOptimizer(\n",
    "        qubo_optimizer=qubo_optimizer,\n",
    "        continuous_optimizer=cont_optimizer,\n",
    "        params=admm_params,\n",
    "    )\n",
    "\n",
    "    # helper interna: constrói QP/QUBO no espaço dos bins\n",
    "    def build_ffcm_admm_qp_hist(\n",
    "        bin_centers: np.ndarray,\n",
    "        V: np.ndarray,\n",
    "    ) -> QuadraticProgram:\n",
    "        \"\"\"\n",
    "        Constrói o QuadraticProgram para FFCM + MBO binário nos bins.\n",
    "        \"\"\"\n",
    "        X_hist = bin_centers.reshape(-1, 1)  # (L,1)\n",
    "        L_loc, K = X_hist.shape             # K=1\n",
    "        C_loc = V.shape[0]\n",
    "\n",
    "        D = np.sum((X_hist[:, None, :] - V[None, :, :])**2, axis=2)  # (L_loc,C_loc)\n",
    "\n",
    "        qp = QuadraticProgram(\"ffcm_mbo_hist\")\n",
    "\n",
    "        for i in range(L_loc):\n",
    "            for k in range(C_loc):\n",
    "                qp.continuous_var(name=f\"u_{i}_{k}\", lowerbound=0.0, upperbound=1.0)\n",
    "                qp.binary_var(name=f\"z_{i}_{k}\")\n",
    "\n",
    "        lin: Dict[str, float] = {}\n",
    "        quad: Dict[tuple, float] = {}\n",
    "\n",
    "        def add_lin(var: str, coeff: float):\n",
    "            if abs(coeff) < 1e-15:\n",
    "                return\n",
    "            lin[var] = lin.get(var, 0.0) + float(coeff)\n",
    "\n",
    "        def add_quad(v1: str, v2: str, coeff: float):\n",
    "            if abs(coeff) < 1e-15:\n",
    "                return\n",
    "            key = (v1, v2)\n",
    "            quad[key] = quad.get(key, 0.0) + float(coeff)\n",
    "\n",
    "        # (1) termo FFCM clássico: sum_i,k w_i * d_{ik} * u_{ik}^2\n",
    "        for i in range(L_loc):\n",
    "            for k in range(C_loc):\n",
    "                ui = f\"u_{i}_{k}\"\n",
    "                add_quad(ui, ui, weights[i] * D[i, k])\n",
    "\n",
    "        # (2) penalização de fuzzy-sum: lambda_s * (sum_k u_{ik} - 1)^2\n",
    "        for i in range(L_loc):\n",
    "            for k in range(C_loc):\n",
    "                uk = f\"u_{i}_{k}\"\n",
    "                add_quad(uk, uk, lambda_s)\n",
    "                for ell in range(k + 1, C_loc):\n",
    "                    ul = f\"u_{i}_{ell}\"\n",
    "                    add_quad(uk, ul, 2.0 * lambda_s)\n",
    "            for k in range(C_loc):\n",
    "                uk = f\"u_{i}_{k}\"\n",
    "                add_lin(uk, -2.0 * lambda_s)\n",
    "\n",
    "        # (3) penalização one-hot binária: mu_s * (sum_k z_{ik} - 1)^2\n",
    "        for i in range(L_loc):\n",
    "            for k in range(C_loc):\n",
    "                zk = f\"z_{i}_{k}\"\n",
    "                add_quad(zk, zk, mu_s)\n",
    "                for ell in range(k + 1, C_loc):\n",
    "                    zl = f\"z_{i}_{ell}\"\n",
    "                    add_quad(zk, zl, 2.0 * mu_s)\n",
    "            for k in range(C_loc):\n",
    "                zk = f\"z_{i}_{k}\"\n",
    "                add_lin(zk, -2.0 * mu_s)\n",
    "\n",
    "        # (4) custo linear em z\n",
    "        for i in range(L_loc):\n",
    "            for k in range(C_loc):\n",
    "                zk = f\"z_{i}_{k}\"\n",
    "                add_lin(zk, alpha * weights[i] * D[i, k])\n",
    "\n",
    "        qp.minimize(linear=lin, quadratic=quad)\n",
    "        return qp\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 4) Laço externo: QFFCM + 3-ADMM-H\n",
    "    # ----------------------------------------------------------------------\n",
    "    U = np.zeros((L, C))\n",
    "    Z = np.zeros((L, C))\n",
    "    rho = admm_params.rho_initial\n",
    "\n",
    "    for it in range(maxiter):\n",
    "        U_old = U.copy()\n",
    "\n",
    "        qp = build_ffcm_admm_qp_hist(bin_centers, V)\n",
    "        print(\"n_binárias (qubits no QAOA):\", qp.get_num_binary_vars())\n",
    "\n",
    "        result = admm.solve(qp)\n",
    "\n",
    "        for i in range(L):\n",
    "            for k in range(C):\n",
    "                U[i, k] = result.variables_dict[f\"u_{i}_{k}\"]\n",
    "                Z[i, k] = result.variables_dict[f\"z_{i}_{k}\"]\n",
    "\n",
    "        # atualização de V (FFCM ponderado)\n",
    "        um = U ** m\n",
    "        w_um = um * weights[:, None]\n",
    "\n",
    "        num = (w_um.T @ bin_centers.reshape(-1, 1))\n",
    "        den = w_um.sum(axis=0).reshape(C, 1) + 1e-12\n",
    "        V = num / den\n",
    "\n",
    "        if np.max(np.abs(U - U_old)) < error:\n",
    "            break\n",
    "\n",
    "        rho *= beta_rho\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 5) Rótulos finais em bins e pixels\n",
    "    # ----------------------------------------------------------------------\n",
    "    labels_bins = np.argmax(U, axis=1)  # (L,)\n",
    "\n",
    "    bin_idx = np.digitize(vals, bin_edges[:-1], right=False)\n",
    "    bin_idx = np.clip(bin_idx, 0, L - 1)\n",
    "\n",
    "    labels_flat = labels_bins[bin_idx]\n",
    "    labels = labels_flat.reshape(H, W)\n",
    "\n",
    "    centers = V.copy()\n",
    "\n",
    "    return labels, centers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2e96be",
   "metadata": {},
   "source": [
    "### Funções de Avaliação de Qualidade:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed561e6",
   "metadata": {},
   "source": [
    "#### Métricas Internas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "83de8d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dunn_index(\n",
    "    features: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    ") -> float:\n",
    "    \"\"\"Calcula uma versão aproximada do índice de Dunn para clusters grandes.\n",
    "\n",
    "    O índice de Dunn original é definido como a razão entre a menor\n",
    "    distância inter‑cluster e o maior diâmetro intra‑cluster【699562914633650†L170-L189】. Ele avalia o quão\n",
    "    separados e compactos estão os clusters: valores maiores indicam melhor\n",
    "    separação entre clusters e menor dispersão dentro dos clusters.\n",
    "\n",
    "    Nesta implementação, para tornar o cálculo viável em imagens com dezenas\n",
    "    de milhares de pontos, a distância inter‑cluster é calculada utilizando os\n",
    "    centróides dos clusters (distância euclidiana mínima entre centros), e o\n",
    "    diâmetro intra‑cluster é aproximado como o dobro da maior distância entre\n",
    "    qualquer ponto do cluster e seu centroide.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features : np.ndarray\n",
    "        Matriz de características de forma (H, W, K) ou (N, K).\n",
    "    labels : np.ndarray\n",
    "        Array de rótulos de clusters (H, W) ou (N,) correspondente aos pontos em\n",
    "        ``features``.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Valor aproximado do índice de Dunn. Quanto maior, melhor a\n",
    "        segmentação.\n",
    "    \"\"\"\n",
    "    # Ajusta dimensões para formato (N, K)\n",
    "    if features.ndim == 3:\n",
    "        X = features.reshape(-1, features.shape[-1])\n",
    "    else:\n",
    "        X = features.reshape(-1, 1)\n",
    "    labels_flat = labels.reshape(-1)\n",
    "    unique_labels = np.unique(labels_flat)\n",
    "    # Calcula centróides\n",
    "    centers = np.stack([\n",
    "        X[labels_flat == lbl].mean(axis=0) if np.any(labels_flat == lbl) else np.zeros(X.shape[1])\n",
    "        for lbl in unique_labels\n",
    "    ])\n",
    "    # Calcula matriz de distâncias entre centróides\n",
    "    dist_centers = pairwise_distances(centers)\n",
    "    # Ignora a diagonal ao buscar o mínimo valor não nulo\n",
    "    np.fill_diagonal(dist_centers, np.inf)\n",
    "    min_inter_cluster = dist_centers.min()\n",
    "    # Calcula diâmetro aproximado de cada cluster: 2 * max(distância ao centro)\n",
    "    max_diameter = 0.0\n",
    "    for idx, lbl in enumerate(unique_labels):\n",
    "        points = X[labels_flat == lbl]\n",
    "        if points.shape[0] <= 1:\n",
    "            continue\n",
    "        center = centers[idx]\n",
    "        distances = np.linalg.norm(points - center, axis=1)\n",
    "        diameter = 2.0 * distances.max()\n",
    "        if diameter > max_diameter:\n",
    "            max_diameter = diameter\n",
    "    if max_diameter == 0:\n",
    "        return np.inf\n",
    "    return float(min_inter_cluster / max_diameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4174f48d",
   "metadata": {},
   "source": [
    "#### Aplicando a Métrica de Dunn e Algumas outras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b029a8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clustering(\n",
    "    features: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    method_name: str,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Calcula índices internos de validação de cluster para uma segmentação.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features : np.ndarray\n",
    "        Matriz de características (H, W, K) ou (H, W).\n",
    "    labels : np.ndarray\n",
    "        Rótulos obtidos para cada ponto (H, W).\n",
    "    method_name : str\n",
    "        Nome do método (para fins informativos). Não interfere no cálculo.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, float]\n",
    "        Dicionário contendo as chaves ``'DB'`` (Davies–Bouldin), ``'DI'``\n",
    "        (Dunn) e ``'CH'`` (Calinski–Harabasz).\n",
    "    \"\"\"\n",
    "    # Ajusta as dimensões do conjunto de pontos\n",
    "    if features.ndim == 2:\n",
    "        X = features[..., None].reshape(-1, 1)\n",
    "    else:\n",
    "        X = features.reshape(-1, features.shape[-1])\n",
    "    y = labels.reshape(-1)\n",
    "    # Davies–Bouldin: média de similaridade de cada cluster com seu cluster mais próximo; valores menores indicam clusters mais compactos【518966911363608†L676-L683】\n",
    "    db = davies_bouldin_score(X, y)\n",
    "    # Calinski–Harabasz: razão entre dispersão inter‑cluster e intra‑cluster\n",
    "    ch = calinski_harabasz_score(X, y)\n",
    "    # Dunn index (aproximado): quanto maior, melhor【699562914633650†L170-L189】\n",
    "    di = dunn_index(features, labels)\n",
    "    return {\"DB\": db, \"CH\": ch, \"DI\": di}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5741fcb3",
   "metadata": {},
   "source": [
    "## Funções Auxiliares(executa a segmentação e mede o desempenho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "38edb2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fcm(\n",
    "    image: np.ndarray,\n",
    "    n_clusters: int = 2,\n",
    "    seed: int = 0,\n",
    "    m: float = 2.0,\n",
    "    error: float = 1e-3,\n",
    "    maxiter: int = 1000,\n",
    "    nbins: int = 8,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Executa segmentação Fuzzy C‑Means e retorna resultados.\n",
    "\n",
    "    Esta função encapsula a chamada ao algoritmo FCM, calcula o tempo de\n",
    "    processamento e avalia a segmentação utilizando ``evaluate_clustering``.\n",
    "    O retorno é um dicionário com campos que podem ser manipulados\n",
    "    independentemente em outros contextos.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.ndarray\n",
    "        Imagem 2‑D normalizada em ``[0,1]``.\n",
    "    n_clusters : int, optional\n",
    "        Número de clusters para segmentação. Padrão: 3.\n",
    "    seed : int, optional\n",
    "        Semente aleatória para reproducibilidade. Padrão: 0.\n",
    "    m : float, optional\n",
    "        Parâmetro de fuzzificação para o FCM. Padrão: 1.6.\n",
    "    error : float, optional\n",
    "        Critério de parada para o FCM. Padrão: 1e‑5.\n",
    "    maxiter : int, optional\n",
    "        Número máximo de iterações para o FCM. Padrão: 1000.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, Any]\n",
    "        Dicionário com as chaves ``'labels'``, ``'centers'``, ``'metrics'`` e\n",
    "        ``'time'``. O campo ``'labels'`` contém a máscara de rótulos (H, W).\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    labels, centers = cmeans_labels(\n",
    "        image,\n",
    "        n_clusters=n_clusters,\n",
    "        m=m,\n",
    "        error=error,\n",
    "        maxiter=maxiter,\n",
    "        seed=seed,\n",
    "        nbins=nbins,\n",
    "    )\n",
    "    elapsed = time.time() - t0\n",
    "    metrics = evaluate_clustering(image, labels, method_name=\"FCM\")\n",
    "    return {\n",
    "        \"labels\": labels,\n",
    "        \"centers\": centers,\n",
    "        \"metrics\": metrics,\n",
    "        \"time\": elapsed,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def run_kmeans(\n",
    "    image: np.ndarray,\n",
    "    n_clusters: int = 3,\n",
    "    seed: int = 0,\n",
    "    n_init: int = 10,\n",
    "    max_iter: int = 300,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Executa segmentação K‑Means e retorna resultados.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.ndarray\n",
    "        Imagem 2‑D normalizada em ``[0,1]``.\n",
    "    n_clusters : int, optional\n",
    "        Número de clusters para segmentação. Padrão: 3.\n",
    "    seed : int, optional\n",
    "        Semente aleatória para reproducibilidade. Padrão: 0.\n",
    "    n_init : int, optional\n",
    "        Número de inicializações para o K‑Means. Padrão: 10.\n",
    "    max_iter : int, optional\n",
    "        Número máximo de iterações para o K‑Means. Padrão: 300.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, Any]\n",
    "        Dicionário com as chaves ``'labels'``, ``'centers'``, ``'metrics'`` e\n",
    "        ``'time'``. O campo ``'labels'`` contém a máscara de rótulos (H, W).\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    labels, centers = kmeans_labels(\n",
    "        image,\n",
    "        n_clusters=n_clusters,\n",
    "        seed=seed,\n",
    "        n_init=n_init,\n",
    "        max_iter=max_iter,\n",
    "    )\n",
    "    elapsed = time.time() - t0\n",
    "    metrics = evaluate_clustering(image, labels, method_name=\"KMeans\")\n",
    "    return {\n",
    "        \"labels\": labels,\n",
    "        \"centers\": centers,\n",
    "        \"metrics\": metrics,\n",
    "        \"time\": elapsed,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb618a09",
   "metadata": {},
   "source": [
    "## Plote das Imagens segmentadas pelo dois métodos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c7ed52f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(\n",
    "    labels_fcm: np.ndarray,\n",
    "    labels_km: np.ndarray,\n",
    "    title_base: str,\n",
    "    out_dir: Path,\n",
    "    cmap: str = \"viridis\",\n",
    ") -> Path:\n",
    "    \"\"\"Plota lado a lado as máscaras de segmentação de FCM e K‑Means.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels_fcm : np.ndarray\n",
    "        Máscara de rótulos obtida com Fuzzy C‑Means (H, W).\n",
    "    labels_km : np.ndarray\n",
    "        Máscara de rótulos obtida com K‑Means (H, W).\n",
    "    title_base : str\n",
    "        Base para o título e nome do arquivo (por exemplo, nome da imagem).\n",
    "    out_dir : Path\n",
    "        Diretório onde a figura será salva.\n",
    "    cmap : str, optional\n",
    "        Paleta de cores utilizada para exibir as máscaras. Padrão: ``'viridis'``.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Path\n",
    "        Caminho do arquivo de imagem salvo.\n",
    "    \"\"\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    # FCM\n",
    "    axes[0].imshow(labels_fcm, cmap=cmap)\n",
    "    axes[0].set_title(f\"{title_base} Index - FCM Segmentation\", fontsize=12)\n",
    "    axes[0].axis(\"off\")\n",
    "    # K‑Means\n",
    "    axes[1].imshow(labels_km, cmap=cmap)\n",
    "    axes[1].set_title(f\"{title_base} Index - K-Means Segmentation\", fontsize=12)\n",
    "    axes[1].axis(\"off\")\n",
    "    # Título geral\n",
    "    fig.suptitle(\n",
    "        \"Segmentation Comparison Between Fuzzy C-Means and K-Means\",\n",
    "        fontsize=14,\n",
    "        y=1.02,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    out_path = out_dir / f\"{title_base}_comparacao.png\"\n",
    "    plt.savefig(out_path, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64a69b9",
   "metadata": {},
   "source": [
    "## Função principal (roda tudo anterior para uma imagem):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5ab304d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_image(\n",
    "    image: np.ndarray,\n",
    "    image_name: str,\n",
    "    n_clusters: int = 2,\n",
    "    out_dir: Path | None = None,\n",
    "    seed: int = 0,\n",
    "    fcm_params: Dict[str, Any] | None = None,\n",
    "    kmeans_params: Dict[str, Any] | None = None,\n",
    "    normalize: Optional[str] = None,              # <- NOVO\n",
    "    norm_params: Optional[Dict[str, float]] = None,  # <- NOVO (para globais)\n",
    ") -> Dict[str, Any]:\n",
    "\n",
    "    # ... dentro da função, antes de chamar run_fcm/run_kmeans:\n",
    "    img_in, used_norm = apply_normalization(image, normalize=normalize, params=norm_params)\n",
    "\n",
    "    fcm_res = run_fcm(\n",
    "        image=img_in,\n",
    "        n_clusters=n_clusters,\n",
    "        seed=seed,\n",
    "        **(fcm_params or {}),\n",
    "    )\n",
    "    km_res = run_kmeans(\n",
    "        image=img_in,\n",
    "        n_clusters=n_clusters,\n",
    "        seed=seed,\n",
    "        **(kmeans_params or {}),\n",
    "    )\n",
    "\n",
    "       # Gera figura comparativa, se desejado.\n",
    "    plot_path = None\n",
    "    if out_dir is not None:\n",
    "        out_dir = Path(out_dir)\n",
    "        plot_path = plot_comparison(\n",
    "            labels_fcm=fcm_res[\"labels\"],\n",
    "            labels_km=km_res[\"labels\"],\n",
    "            title_base=image_name,\n",
    "            out_dir=out_dir,\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"fcm\": fcm_res,\n",
    "        \"kmeans\": km_res,\n",
    "        \"plot_path\": plot_path,\n",
    "        \"normalization\": used_norm,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede1d606",
   "metadata": {},
   "source": [
    "### Roda tudo para multiplas Imagens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f5948b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batch(\n",
    "    image_paths: List[Path],\n",
    "    n_clusters: int = 2,\n",
    "    seed: int = 0,\n",
    "    fcm_params: Dict[str, Any] | None = None,\n",
    "    kmeans_params: Dict[str, Any] | None = None,\n",
    "    out_dir: Path | None = None,\n",
    "    normalize: Optional[str] = None,                 # <- NOVO\n",
    "    norm_params: Optional[Dict[str, float]] = None,  # <- NOVO\n",
    ") -> List[Tuple[str, Dict[str, Any]]]:\n",
    "    \"\"\"Processa uma lista de imagens, aplicando segmentação e retornando resultados.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image_paths : list of Path\n",
    "            Lista de caminhos das imagens a serem segmentadas.\n",
    "        n_clusters : int, optional\n",
    "            Número de clusters para segmentação. Padrão: 3.\n",
    "        seed : int, optional\n",
    "            Semente aleatória para reproducibilidade. Padrão: 0.\n",
    "        fcm_params : dict, optional\n",
    "            Parâmetros adicionais para ``run_fcm``.\n",
    "        kmeans_params : dict, optional\n",
    "            Parâmetros adicionais para ``run_kmeans``.\n",
    "        out_dir : Path, optional\n",
    "            Diretório onde as figuras de comparação serão salvas. Se ``None``,\n",
    "            figuras não serão geradas.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        List[Tuple[str, Dict[str, Any]]]\n",
    "            Lista de tuplas com o nome da imagem e o dicionário de resultados\n",
    "            retornado por ``segment_image``.\n",
    "        \"\"\"\n",
    "    results = []\n",
    "    for path in image_paths:\n",
    "        img = np.asarray(Image.open(path).convert(\"L\"), dtype=np.float32)  # sem normalizar\n",
    "        name = path.stem\n",
    "        res = segment_image(\n",
    "            image=img,\n",
    "            image_name=name,\n",
    "            n_clusters=n_clusters,\n",
    "            out_dir=out_dir,\n",
    "            seed=seed,\n",
    "            fcm_params=fcm_params,\n",
    "            kmeans_params=kmeans_params,\n",
    "            normalize=normalize,          # <- NOVO\n",
    "            norm_params=norm_params,      # <- NOVO\n",
    "        )\n",
    "        results.append((name, res))\n",
    "    return results\n",
    "\n",
    "def run_batch_arrays(\n",
    "    images: List[np.ndarray],\n",
    "    names: List[str] | None = None,\n",
    "    n_clusters: int = 3,\n",
    "    seed: int = 0,\n",
    "    fcm_params: Dict[str, Any] | None = None,\n",
    "    kmeans_params: Dict[str, Any] | None = None,\n",
    "    out_dir: Path | None = None,\n",
    "    normalize: Optional[str] = None,\n",
    "    norm_params: Optional[Dict[str, float]] = None,\n",
    ") -> List[Tuple[str, Dict[str, Any]]]:\n",
    "    if names is None:\n",
    "        names = [f\"img_{i}\" for i in range(len(images))]\n",
    "\n",
    "    results: List[Tuple[str, Dict[str, Any]]] = []\n",
    "    for name, img in zip(names, images):\n",
    "        res = segment_image(\n",
    "            image=img.astype(np.float32),\n",
    "            image_name=name,\n",
    "            n_clusters=n_clusters,\n",
    "            out_dir=out_dir,\n",
    "            seed=seed,\n",
    "            fcm_params=fcm_params,\n",
    "            kmeans_params=kmeans_params,\n",
    "            normalize=normalize,\n",
    "            norm_params=norm_params,\n",
    "        )\n",
    "        results.append((name, res))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a26ac2",
   "metadata": {},
   "source": [
    "### Função que mostra os Resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "024ce39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def print_results(results: List[Tuple[str, Dict[str, Any]]]) -> None:\n",
    "    \"\"\"Imprime uma tabela comparativa de índices e tempos de segmentações.\n",
    "\n",
    "    Esta função recebe a lista retornada por ``run_batch`` e exibe uma tabela\n",
    "    formatada no console com os valores de Davies–Bouldin, Dunn, Calinski–Harabasz\n",
    "    e tempo de processamento para cada método e cada imagem.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    results : list of (str, dict)\n",
    "        Lista de tuplas com o nome da imagem e o dicionário de resultados.\n",
    "    \"\"\"\n",
    "    print(\"\\nTabela comparativa de índices e tempos:\\n\")\n",
    "    header = f\"{'Imagem':<15} | {'Método':<7} | {'DB':>10} | {'DI':>10} | {'CH':>10} | {'Tempo (s)':>10}\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "    for name, res in results:\n",
    "        # FCM\n",
    "        fm = res[\"fcm\"][\"metrics\"]\n",
    "        print(\n",
    "            f\"{name:<15} | {'FCM':<7} | {fm['DB']:>10.4f} | {fm['DI']:>10.4f} | {fm['CH']:>10.4f} | {res['fcm']['time']:>10.4f}\"\n",
    "        )\n",
    "        # K‑Means\n",
    "        km = res[\"kmeans\"][\"metrics\"]\n",
    "        print(\n",
    "            f\"{name:<15} | {'KMeans':<7} | {km['DB']:>10.4f} | {km['DI']:>10.4f} | {km['CH']:>10.4f} | {res['kmeans']['time']:>10.4f}\"\n",
    "        )\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64ec0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7eeeaa4",
   "metadata": {},
   "source": [
    "# Metricas Externas de Comparação(Usando GroundTruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "75509753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hausdorff_distance(ground: np.ndarray, seg: np.ndarray) -> float:\n",
    "    \"\"\"Calcula a distância de Hausdorff (bidirecional) entre duas máscaras binárias.\n",
    "\n",
    "    A métrica considera a maior distância entre os pixels do conjunto A até o pixel mais próximo\n",
    "    no conjunto B e vice‑versa. Quando uma das máscaras está vazia (sem pixels verdadeiros),\n",
    "    retorna ``np.inf`` indicando que a distância é indefinida.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ground : np.ndarray\n",
    "        Máscara de referência (ground truth). Valores não‑zero são considerados positivos.\n",
    "    seg : np.ndarray\n",
    "        Máscara de segmentação obtida. Valores não‑zero são considerados positivos.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Distância de Hausdorff entre as duas máscaras.\n",
    "    \"\"\"\n",
    "    # Converte as entradas em booleano (True para pixel de interesse)\n",
    "    a = ground.astype(bool)\n",
    "    b = seg.astype(bool)\n",
    "    if a.shape != b.shape:\n",
    "        raise ValueError(\"As dimensões de 'ground' e 'seg' devem ser iguais para o cálculo da Hausdorff.\")\n",
    "    # Se um dos conjuntos estiver vazio, a distância é infinita (não há comparação possível)\n",
    "    if not np.any(a) or not np.any(b):\n",
    "        return float('inf')\n",
    "    # Distância transform da máscara negativa de b: para cada pixel, distância até o pixel mais próximo em b\n",
    "    dt_b = distance_transform_edt(~b)\n",
    "    # Distância de cada ponto em a até o conjunto b\n",
    "    dist_a_to_b = dt_b[a]\n",
    "    max_a_to_b = dist_a_to_b.max() if dist_a_to_b.size > 0 else 0.0\n",
    "    # Distância transform de a\n",
    "    dt_a = distance_transform_edt(~a)\n",
    "    dist_b_to_a = dt_a[b]\n",
    "    max_b_to_a = dist_b_to_a.max() if dist_b_to_a.size > 0 else 0.0\n",
    "    return float(max(max_a_to_b, max_b_to_a))\n",
    "\n",
    "\n",
    "def dice_coefficient(ground: np.ndarray, seg: np.ndarray) -> float:\n",
    "    \"\"\"Calcula o coeficiente de Dice entre duas máscaras binárias.\n",
    "\n",
    "    O coeficiente de Dice (F1 score para conjuntos) é definido como:\n",
    "\n",
    "    .. math:: \text{Dice}(A, B) = \f",
    "rac{2|A \\cap B|}{|A| + |B|}\n",
    "\n",
    "    onde |A| e |B| são os números de pixels positivos em cada máscara.\n",
    "\n",
    "    Retorna 1.0 quando ambos os conjuntos são vazios.\n",
    "    \"\"\"\n",
    "    a = ground.astype(bool)\n",
    "    b = seg.astype(bool)\n",
    "    intersection = np.logical_and(a, b).sum()\n",
    "    size_a = a.sum()\n",
    "    size_b = b.sum()\n",
    "    # Se ambas as máscaras forem vazias, retorna 1 (acordo perfeito)\n",
    "    if size_a + size_b == 0:\n",
    "        return 1.0\n",
    "    return 2.0 * intersection / float(size_a + size_b)\n",
    "\n",
    "\n",
    "def iou_coefficient(ground: np.ndarray, seg: np.ndarray) -> float:\n",
    "    \"\"\"Calcula o coeficiente Intersection over Union (IoU) ou índice de Jaccard.\n",
    "\n",
    "    O IoU é definido como:\n",
    "\n",
    "    .. math:: \text{IoU}(A, B) = \f",
    "rac{|A \\cap B|}{|A \\cup B|}\n",
    "\n",
    "    onde |A \\cup B| é o número de pixels que pertencem a pelo menos uma das máscaras.\n",
    "\n",
    "    Retorna 1.0 quando ambos os conjuntos são vazios.\n",
    "    \"\"\"\n",
    "    a = ground.astype(bool)\n",
    "    b = seg.astype(bool)\n",
    "    intersection = np.logical_and(a, b).sum()\n",
    "    union = np.logical_or(a, b).sum()\n",
    "    if union == 0:\n",
    "        return 1.0\n",
    "    return intersection / float(union)\n",
    "\n",
    "\n",
    "def validacao_metricas_externas(ground: np.ndarray, segmentado: np.ndarray) -> dict:\n",
    "    \"\"\"Calcula métricas externas de avaliação de segmentação.\n",
    "\n",
    "    Esta função consolida três métricas comumente utilizadas para avaliar a\n",
    "    concordância entre uma segmentação e a segmentação de referência:\n",
    "\n",
    "    * \"Hausdorff\": distância de Hausdorff bidirecional entre as máscaras;\n",
    "    * \"Dice\": coeficiente de Dice (também conhecido como F1 score em segmentação);\n",
    "    * \"IoU\": Intersection over Union (índice de Jaccard).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ground : np.ndarray\n",
    "        Máscara de referência (ground truth). Qualquer valor não‑zero será interpretado como pixel positivo.\n",
    "    segmentado : np.ndarray\n",
    "        Máscara segmentada a ser validada. Valores não‑zero serão interpretados como pixel positivo.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dicionário com as métricas calculadas, contendo as chaves \"Hausdorff\", \"Dice\" e \"IoU\".\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'Hausdorff': hausdorff_distance(ground, segmentado),\n",
    "        'Dice': dice_coefficient(ground, segmentado),\n",
    "        'IoU': iou_coefficient(ground, segmentado),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250316ef",
   "metadata": {},
   "source": [
    "# Importando dados e Testando local:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ec90942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "linha = 0\n",
    "\n",
    "data = np.load(f\"Imagens_e_indices/Image[{linha}]/Image[{linha}]indices_diff.npz\")\n",
    "\n",
    "img_diff_ndvi = data[\"diff_ndvi\"].astype(np.float32)\n",
    "img_diff_nbr = data[\"diff_nbr\"].astype(np.float32)\n",
    "img_diff_nbrswir = data[\"diff_nbrswir\"].astype(np.float32)\n",
    "\n",
    "imagens = [\n",
    "    img_diff_nbr,\n",
    "    img_diff_ndvi,\n",
    "    img_diff_nbrswir]\n",
    "\n",
    "fcm_params = {\n",
    "    \"m\": 2.0,        # grau de fuzzificação\n",
    "    \"maxiter\": 500,  # número máximo de iterações\n",
    "}\n",
    "\n",
    "\n",
    "res = segment_image(\n",
    "    image=img_diff_nbrswir,\n",
    "    image_name=\"imagem_NBRswir\",\n",
    "    n_clusters=2,\n",
    "    out_dir=None,\n",
    "    seed=0,\n",
    "    fcm_params=fcm_params,\n",
    "    kmeans_params=None,\n",
    "    normalize=None,\n",
    "    norm_params=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b4cf12-163f-44b3-a694-e635b1dc7710",
   "metadata": {},
   "source": [
    "# Salvando todas as imagens e tabelas de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d593419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_images(\n",
    "    root_dir: Path,\n",
    "    out_root: Path,\n",
    "    n_clusters: int = 2,\n",
    "    seed: int = 0,\n",
    "    normalize: Optional[str] = \"minmax\",\n",
    ") -> List[Dict[str, Any]]:\n",
    "    out_root.mkdir(parents=True, exist_ok=True)\n",
    "    metric_rows: List[Dict[str, Any]] = []\n",
    "\n",
    "    image_dirs = sorted(\n",
    "        p for p in root_dir.iterdir()\n",
    "        if p.is_dir() and p.name.startswith(\"Image\")\n",
    "    )\n",
    "\n",
    "    if not image_dirs:\n",
    "        print(f\"Nenhuma pasta 'Image[...]' encontrada em {root_dir}\")\n",
    "        return metric_rows\n",
    "\n",
    "    for img_dir in image_dirs:\n",
    "        img_id = img_dir.name\n",
    "        print(f\"\\n=== Processando {img_id} ===\")\n",
    "\n",
    "        gt_candidates = sorted(img_dir.glob(\"*GroundTruth*.npz\"))\n",
    "        idx_candidates = sorted(img_dir.glob(\"*indices*.npz\"))\n",
    "\n",
    "        if not gt_candidates or not idx_candidates:\n",
    "            print(f\"  [AVISO] Pulando {img_id}: não achei GroundTruth/indices_diff .npz\")\n",
    "            continue\n",
    "\n",
    "        gt_path = gt_candidates[0]\n",
    "        idx_path = idx_candidates[0]\n",
    "\n",
    "        print(f\"  Ground truth : {gt_path.name}\")\n",
    "        print(f\"  Índices      : {idx_path.name}\")\n",
    "\n",
    "        gt_npz = np.load(gt_path)\n",
    "        gt_key = gt_npz.files[0]\n",
    "        gt_array = gt_npz[gt_key]\n",
    "        ground_bin = (gt_array > 0).astype(np.uint8)\n",
    "\n",
    "        indices_npz = np.load(idx_path)\n",
    "\n",
    "        for index_name in indices_npz.files:\n",
    "            idx_img = indices_npz[index_name].astype(np.float32)\n",
    "\n",
    "            if idx_img.shape != ground_bin.shape:\n",
    "                print(\n",
    "                    f\"  [AVISO] Índice '{index_name}' shape {idx_img.shape} \"\n",
    "                    f\"diferente da GT {ground_bin.shape}. Pulando.\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            print(f\"  -> Índice: {index_name} (shape={idx_img.shape})\")\n",
    "\n",
    "            full_name = f\"{img_id}_{index_name}\"\n",
    "            pair_out_dir = out_root / img_id / index_name\n",
    "\n",
    "            fcm_params = {\n",
    "                \"m\": 2.0,\n",
    "                \"error\": 1e-3,   # error = 1e-3\n",
    "                \"maxiter\": 15,\n",
    "                \"nbins\": 8,\n",
    "            }\n",
    "            kmeans_params = {\n",
    "                \"n_init\": 10,\n",
    "                \"max_iter\": 300,\n",
    "            }\n",
    "\n",
    "            res = segment_image(\n",
    "                image=idx_img,\n",
    "                image_name=full_name,\n",
    "                n_clusters=n_clusters,\n",
    "                out_dir=pair_out_dir,\n",
    "                seed=seed,\n",
    "                fcm_params=fcm_params,\n",
    "                kmeans_params=kmeans_params,\n",
    "                normalize=normalize,\n",
    "                norm_params=None,\n",
    "            )\n",
    "            \n",
    "            print(f\"  [OK] Segmentação QFFCM + KMeans concluída para {full_name}\", flush=True)\n",
    "\n",
    "            fcm_labels = res[\"fcm\"][\"labels\"]\n",
    "            km_labels = res[\"kmeans\"][\"labels\"]\n",
    "\n",
    "            fcm_bin = (fcm_labels != 0).astype(np.uint8)\n",
    "            km_bin = (km_labels != 0).astype(np.uint8)\n",
    "\n",
    "            fcm_bin = maybe_flip_binary(fcm_bin, ground_bin)\n",
    "            km_bin = maybe_flip_binary(km_bin, ground_bin)\n",
    "\n",
    "            ext_fcm = validacao_metricas_externas(ground_bin, fcm_bin)\n",
    "            ext_km = validacao_metricas_externas(ground_bin, km_bin)\n",
    "\n",
    "            int_fcm = res[\"fcm\"][\"metrics\"]\n",
    "            int_km = res[\"kmeans\"][\"metrics\"]\n",
    "\n",
    "            metric_rows.append({\n",
    "                \"image\": img_id,\n",
    "                \"index\": index_name,\n",
    "                \"method\": \"QFFCM\",\n",
    "                \"DB\": int_fcm[\"DB\"],\n",
    "                \"DI\": int_fcm[\"DI\"],\n",
    "                \"CH\": int_fcm[\"CH\"],\n",
    "                \"Hausdorff\": ext_fcm[\"Hausdorff\"],\n",
    "                \"Dice\": ext_fcm[\"Dice\"],\n",
    "                \"IoU\": ext_fcm[\"IoU\"],\n",
    "                \"time_seconds\": res[\"fcm\"][\"time\"],\n",
    "            })\n",
    "\n",
    "            metric_rows.append({\n",
    "                \"image\": img_id,\n",
    "                \"index\": index_name,\n",
    "                \"method\": \"KMeans\",\n",
    "                \"DB\": int_km[\"DB\"],\n",
    "                \"DI\": int_km[\"DI\"],\n",
    "                \"CH\": int_km[\"CH\"],\n",
    "                \"Hausdorff\": ext_km[\"Hausdorff\"],\n",
    "                \"Dice\": ext_km[\"Dice\"],\n",
    "                \"IoU\": ext_km[\"IoU\"],\n",
    "                \"time_seconds\": res[\"kmeans\"][\"time\"],\n",
    "            })\n",
    "\n",
    "    return metric_rows\n",
    "\n",
    "def salvar_tabela_metricas(metric_rows: List[Dict[str, Any]], out_root: Path) -> None:\n",
    "    if not metric_rows:\n",
    "        print(\"Nenhuma métrica para salvar.\")\n",
    "        return\n",
    "\n",
    "    out_root.mkdir(parents=True, exist_ok=True)\n",
    "    csv_path = out_root / \"metricas_segmentacao.csv\"\n",
    "\n",
    "    try:\n",
    "        import pandas as pd\n",
    "    except ImportError:\n",
    "        keys = list(metric_rows[0].keys())\n",
    "        with csv_path.open(\"w\", newline=\"\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=keys)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(metric_rows)\n",
    "        print(f\"Tabela de métricas salva em (sem pandas): {csv_path}\")\n",
    "    else:\n",
    "        df = pd.DataFrame(metric_rows)\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\"Tabela de métricas salva em: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b3423e-3333-4665-ae4c-bd08bc88324d",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1e188e-0abf-44dd-a084-a3c2e0d536e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    base_dir = Path(\"Imagens_e_indices\")\n",
    "    resultados_dir = Path(\"Resultados_segmentacao\")\n",
    "\n",
    "    metric_rows = process_all_images(\n",
    "        root_dir=base_dir,\n",
    "        out_root=resultados_dir,\n",
    "        n_clusters=2,\n",
    "        seed=0,\n",
    "        normalize=\"minmax\"\n",
    "    )\n",
    "\n",
    "    salvar_tabela_metricas(metric_rows, resultados_dir)\n",
    "    print(\"\\nProcessamento concluído.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
